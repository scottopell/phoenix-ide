# Phoenix IDE Frontend Performance Analysis

## Phase 1: Discovery & Analysis Report

### 1. List of All API Endpoints Called by Frontend

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/conversations` | GET | List active conversations |
| `/api/conversations/archived` | GET | List archived conversations |
| `/api/conversations/new` | POST | Create new conversation |
| `/api/conversations/by-slug/{slug}` | GET | Get conversation details by slug |
| `/api/conversations/{id}/chat` | POST | Send a message |
| `/api/conversations/{id}/cancel` | POST | Cancel ongoing operation |
| `/api/conversations/{id}/archive` | POST | Archive conversation |
| `/api/conversations/{id}/unarchive` | POST | Unarchive conversation |
| `/api/conversations/{id}/delete` | POST | Delete conversation |
| `/api/conversations/{id}/rename` | POST | Rename conversation |
| `/api/conversations/{id}/stream` | SSE | Real-time event stream |
| `/api/validate-cwd` | GET | Validate directory path |
| `/api/list-directory` | GET | List directory contents |
| `/api/models` | GET | Get available models |

### 2. Request Lifecycle Analysis

#### **ConversationListPage**
- **Trigger**: Component mount (`useEffect`)
- **Frequency**: Every time user navigates to `/`
- **Requests**: 
  - `GET /api/conversations` (active conversations)
  - `GET /api/conversations/archived` (archived conversations)
- **Caching**: ❌ None - data discarded on unmount
- **State**: Local React state only

#### **ConversationPage**
- **Trigger**: Component mount when navigating to `/c/{slug}`
- **Frequency**: Every time user opens a conversation
- **Requests**:
  - `GET /api/conversations/by-slug/{slug}` (initial load)
  - `EventSource /api/conversations/{id}/stream` (SSE connection)
- **Caching**: ❌ None - all data fetched fresh
- **State**: Local React state + SSE updates

#### **SSE Connection**
- **Trigger**: After initial conversation load
- **Reconnection**: Automatic with exponential backoff (via `useConnection` hook)
- **Deduplication**: Tracks `sequence_id` to avoid duplicate messages
- **Smart Reconnection**: Uses `?after={sequence_id}` parameter

### 3. Current State Management Approach

**No Global State Management**
- No Redux, Zustand, or React Context for data
- Each page component manages its own state independently
- Data is completely lost when navigating between routes

**Local Storage Usage** (minimal):
- `phoenix:draft:{conversationId}` - Draft message text (auto-saved with debounce)
- Theme preference (dark/light mode)
- No conversation data or caching

**API Client**:
- Simple fetch wrapper in `api.ts`
- No request caching
- No response caching
- No request deduplication

### 4. Identified Inefficiencies

1. **Complete Data Loss on Navigation**
   - User views conversation → clicks back → ALL conversations refetched
   - No memory of previously loaded data
   - Network requests for data that was just displayed seconds ago

2. **Redundant Initial Loads**
   - Opening a conversation fetches all messages via REST
   - Then SSE connection sends `init` event with same messages
   - Potential for duplicate rendering

3. **No Request Deduplication**
   - If user rapidly navigates back/forth, multiple identical requests fire
   - No cancellation of in-flight requests

4. **Archive Toggle Inefficiency**
   - Both active AND archived conversations fetched on every page load
   - Even if user never views archived conversations

5. **No Optimistic Updates**
   - Operations like archive/delete reload entire list
   - Could update UI immediately while request processes

### 5. Questions for You

1. **Performance Priorities**
   - Which scenario is most critical: slow initial load or navigation sluggishness?
   - Are users typically working with many conversations (100+) or fewer?
   - How often do users navigate back and forth between list and conversations?

2. **Caching Strategy**
   - How fresh does conversation list data need to be? Can we cache for X minutes?
   - Should we implement stale-while-revalidate patterns?
   - Is offline functionality a future consideration?

3. **State Management Preference**
   - Open to adding a state management library (Redux Toolkit, Zustand)?
   - Or prefer keeping it simple with React Query/SWR for caching?
   - Or custom caching solution to minimize dependencies?

4. **UX Expectations**
   - Should navigating "back" restore scroll position and previous state?
   - How should we handle updates that occur while user is viewing cached data?
   - Priority: instant navigation vs. always-fresh data?

5. **Scope Boundaries**
   - Focus only on conversation list ↔ conversation navigation?
   - Also optimize other flows (archive operations, model fetching)?
   - Consider implementing virtual scrolling for large conversation lists?

### Additional Findings

**Request Patterns**:
- ConversationListPage makes 2 parallel requests on mount (active + archived)
- No pagination - all conversations loaded at once
- Models endpoint called on NewConversationModal mount only

**Memory Patterns**:
- Messages array grows unbounded during long conversations
- No message pagination or windowing
- All messages kept in component state even if scrolled out of view

**Network Patterns**:
- No compression headers observed in API client
- No ETag/If-None-Match conditional requests
- No HTTP caching headers utilized

**Next Steps**: Once you provide guidance on these questions, I'll propose specific optimization solutions with tradeoffs for Phase 2.

## Phase 2: Proposed Solutions

### Core Architecture: Offline-First State Machine

Based on your requirements, I propose a **layered state machine architecture** that mirrors the backend's approach:

```
┌─────────────────────────────────────────────────┐
│                  UI Components                   │
├─────────────────────────────────────────────────┤
│              State Machines Layer               │
│  ┌─────────────┐ ┌──────────────┐ ┌─────────┐  │
│  │ AppMachine  │ │ ConvMachine  │ │ Others  │  │
│  │ (routing,   │ │ (messages,   │ │  ...    │  │
│  │  sync)      │ │  SSE)        │ │         │  │
│  └─────────────┘ └──────────────┘ └─────────┘  │
├─────────────────────────────────────────────────┤
│               Cache Layer (IndexedDB)            │
│  - Conversations, Messages, Models              │
│  - Optimistic writes with conflict resolution   │
│  - Background sync queue                        │
├─────────────────────────────────────────────────┤
│                  API Client                      │
│  - Request deduplication                        │
│  - Compression (Brotli/gzip)                    │
│  - Retry with exponential backoff              │
└─────────────────────────────────────────────────┘
```

### 1. State Machine Design

#### AppMachine (Global App State)
```typescript
type AppState = 
  | { type: 'initializing' }
  | { type: 'online'; syncStatus: SyncStatus }
  | { type: 'offline'; pendingOps: Operation[] }
  | { type: 'syncing'; progress: number };

type AppEvent =
  | { type: 'NETWORK_ONLINE' }
  | { type: 'NETWORK_OFFLINE' }
  | { type: 'SYNC_STARTED' }
  | { type: 'SYNC_PROGRESS'; progress: number }
  | { type: 'SYNC_COMPLETED' }
  | { type: 'OPERATION_QUEUED'; op: Operation };
```

#### ConversationListMachine
```typescript
type ListState =
  | { type: 'idle'; data: CachedWithMeta<Conversation[]> }
  | { type: 'loading' }
  | { type: 'revalidating'; data: CachedWithMeta<Conversation[]> }
  | { type: 'error'; error: Error; cachedData?: Conversation[] };

type CachedWithMeta<T> = {
  data: T;
  timestamp: number;
  etag?: string;
  scrollPosition?: number;
};
```

### 2. Caching Strategy: IndexedDB + Memory

**Why IndexedDB?**
- Persists across sessions (subway scenario)
- Stores megabytes of data (messages with images)
- Structured queries
- Works offline

**Cache Design:**
```typescript
// IndexedDB schema
interface CacheDB {
  conversations: {
    key: string; // id
    value: Conversation & { _meta: CacheMeta };
    indexes: { 'by-slug': string; 'by-updated': Date };
  };
  messages: {
    key: [string, number]; // [conversationId, sequenceId]
    value: Message;
    indexes: { 'by-conversation': string };
  };
  pendingOps: {
    key: string; // uuid
    value: PendingOperation;
    indexes: { 'by-created': Date };
  };
}

// Memory cache for hot data
class MemoryCache {
  private conversations = new Map<string, CachedWithMeta<Conversation>>();
  private messages = new Map<string, Message[]>(); // last N messages per conv
  private maxAge = 5 * 60 * 1000; // 5 minutes
  
  // Stale-while-revalidate pattern
  get(key: string): { data: T; stale: boolean } | null {
    const cached = this.conversations.get(key);
    if (!cached) return null;
    
    const age = Date.now() - cached.timestamp;
    return {
      data: cached.data,
      stale: age > this.maxAge
    };
  }
}
```

### 3. Network & Sync Layer

**Sync Queue for Offline Operations:**
```typescript
class SyncQueue {
  private db: IDBDatabase;
  private processing = false;
  
  async enqueue(op: Operation) {
    // Store in IndexedDB
    await this.db.add('pendingOps', {
      id: uuid(),
      operation: op,
      createdAt: new Date(),
      retryCount: 0
    });
    
    // Try to process immediately if online
    if (navigator.onLine) {
      this.process();
    }
  }
  
  async process() {
    if (this.processing) return;
    this.processing = true;
    
    try {
      const pending = await this.db.getAll('pendingOps');
      for (const op of pending) {
        try {
          await this.executeOperation(op);
          await this.db.delete('pendingOps', op.id);
        } catch (err) {
          if (isRetryable(err)) {
            op.retryCount++;
            await this.db.put('pendingOps', op);
          }
        }
      }
    } finally {
      this.processing = false;
    }
  }
}
```

### 4. Navigation Performance

**Instant Navigation with Background Updates:**
```typescript
// ConversationListPage
function ConversationListPage() {
  const { state, send } = useListMachine();
  
  useEffect(() => {
    // Always show cached data immediately
    send({ type: 'LOAD' });
    
    // Revalidate in background if stale
    if (state.data?.stale) {
      send({ type: 'REVALIDATE' });
    }
  }, []);
  
  // Restore scroll position
  useEffect(() => {
    if (state.type === 'idle' && state.data.scrollPosition) {
      window.scrollTo(0, state.data.scrollPosition);
    }
  }, [state]);
}
```

### 5. State Merging Strategy

**CRDT-Inspired Merge Rules:**
```typescript
function mergeConversations(local: Conversation[], remote: Conversation[]): Conversation[] {
  const merged = new Map<string, Conversation>();
  
  // Start with local (has offline changes)
  local.forEach(conv => merged.set(conv.id, conv));
  
  // Apply remote updates
  remote.forEach(remoteConv => {
    const localConv = merged.get(remoteConv.id);
    if (!localConv) {
      // New conversation from remote
      merged.set(remoteConv.id, remoteConv);
    } else {
      // Merge: remote wins for most fields, but preserve local pending ops
      merged.set(remoteConv.id, {
        ...remoteConv,
        _localPending: localConv._localPending
      });
    }
  });
  
  return Array.from(merged.values());
}
```

### 6. Implementation Priority

**Phase 2a: Foundation (Week 1)**
1. Add compression to API responses (Brotli with gzip fallback)
2. Implement IndexedDB cache layer
3. Create AppMachine for global state

**Phase 2b: Navigation (Week 2)**
1. Add memory cache with stale-while-revalidate
2. Implement scroll position restoration
3. Add request deduplication

**Phase 2c: Offline (Week 3)**
1. Implement SyncQueue for offline operations
2. Add pending operation UI indicators
3. Handle conflict resolution

### 7. API Changes Needed

**Backend Compression:**
```rust
// In api/handlers.rs
use tower_http::compression::CompressionLayer;

Router::new()
  .layer(CompressionLayer::new()
    .br(true)  // Brotli
    .gzip(true)
    .deflate(true))
```

**Add ETag Support:**
```rust
// Return ETag header
headers.insert("ETag", HeaderValue::from_str(&conversation_hash)?);

// Check If-None-Match
if let Some(etag) = headers.get("If-None-Match") {
  if etag == current_hash {
    return Ok(StatusCode::NOT_MODIFIED);
  }
}
```

### 8. Testing Strategy

**State Machine Property Tests:**
```typescript
// Similar to backend approach
describe('AppMachine invariants', () => {
  test('offline state always has pending ops or transitions to online', ...);
  test('sync progress monotonically increases', ...);
  test('no operations lost during state transitions', ...);
});
```

**Offline Scenario Tests:**
```typescript
test('subway scenario: queue messages while offline', async () => {
  // Go offline
  await simulateOffline();
  
  // Queue messages to multiple conversations
  await sendMessage(conv1, "Response 1");
  await sendMessage(conv2, "Response 2");
  
  // Verify UI shows pending state
  expect(getConvState(conv1)).toBe('pending');
  
  // Go online
  await simulateOnline();
  
  // Verify messages sent in order
  await waitFor(() => {
    expect(getConvState(conv1)).toBe('sent');
    expect(getConvState(conv2)).toBe('sent');
  });
});
```

### Questions Before Implementation

1. **Cache Invalidation**: How should we handle cache invalidation? Time-based (5 min)? Event-based (SSE notifications)? Both?

2. **Conflict Resolution**: For the "single user multiple devices" scenario, should newer timestamp always win? Or do we need more sophisticated resolution?

3. **Storage Limits**: IndexedDB has limits (~50% of free disk). How should we handle cleanup? LRU for messages? Time-based?

4. **Message Pagination**: Should we implement message windowing now or defer? It would help with memory usage in long conversations.

5. **Progressive Enhancement**: Should the app work without IndexedDB (falls back to memory-only cache)? Some browsers/modes restrict it.

## Implementation Progress

### Phase 2a: Foundation ✅ COMPLETE

1. **Compression Added** ✅
   - Backend now supports Brotli, gzip, deflate, and zstd
   - Test results: 85% reduction in payload size (39KB → 6KB)
   - No frontend changes needed - browsers handle automatically

2. **IndexedDB Cache Layer** ✅
   - Created `cache.ts` with full IndexedDB implementation
   - Stores conversations, messages, and pending operations
   - Includes storage management (purge after 30 days)
   - Tracks metadata (timestamp, etag, scroll position)

3. **AppMachine State Machine** ✅
   - Created `appMachine.ts` for global state management
   - Handles online/offline transitions
   - Manages sync queue with exponential backoff
   - Provides honest UI states (no optimistic updates)

4. **Additional Foundation Work** ✅
   - Memory cache with 5-minute TTL
   - Sync queue for offline operations
   - Enhanced API client with caching integration
   - Request deduplication

### Next Steps: Phase 2b - Navigation Performance

The foundation is now in place. The next phase involves:

1. **Update ConversationListPage** to use enhancedApi
   - Show cached data immediately
   - Background refresh if stale
   - Restore scroll position

2. **Update ConversationPage** to use cached data
   - Instant load from cache
   - Integrate with existing SSE connection logic

3. **Add UI indicators**
   - Offline badge when network is down
   - Sync progress indicator
   - "Updated X minutes ago" timestamps

4. **Testing**
   - Verify instant navigation
   - Test offline message queueing
   - Ensure cache invalidation works correctly

### Code Structure

```
ui/src/
├── cache.ts              # IndexedDB persistence
├── memoryCache.ts        # Fast in-memory cache
├── enhancedApi.ts        # API wrapper with caching
├── syncQueue.ts          # Offline operation handling
├── machines/
│   └── appMachine.ts     # Global state machine
└── hooks/
    └── useAppMachine.ts  # React hook for app state
```
